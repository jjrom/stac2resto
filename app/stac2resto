#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# STAC ingester for resto
#
# Takes an input STAC catalog root url and ingest items recursively into target resto endpoint
# 

import sys
import json
import re
import requests
import urllib3
import time
import os
import validators
import signal
import logging
import argparse
import textwrap

from colorlog import ColoredFormatter

from environs import Env
from requests.adapters import HTTPAdapter
from requests.auth import HTTPBasicAuth
from urllib3.util import Retry

from tqdm import tqdm

# ########### Usage ##########################################################
USAGE = """stac2resto - Takes an input STAC catalog root url and ingest items recursively into target resto endpoint

    Usage:

        stac2resto STAC_URL [options]

    Where:
    
        STAC_URL is either:
        
            * a local catalog endpoint (e.g. /data/catalog.json)
            * a remote catalog endpoint (e.g. https://tamn.snapplanet.io)

        
    Optional arguments:

        --RESTO_URL                 resto endpoint. Default is "http://host.docker.internal:5252"
        --COLLECTION_DEFAULT_MODEL  Default model to apply to new collection if not present in collection.json file (Default is "DefaultModel")
        --INGEST_STRATEGY           Ingest strategy defines what is ingested i.e. "collection", "feature", "both" or "none" (Default is "collection")
        --DEVEL                     Set DEVEL mode on (i.e. deactivate ssl and be verbose)
              
"""

def usage(err = None):
    print(textwrap.dedent(USAGE))
    if logger and err:
        logger.error(err)
    sys.exit(1)

def kill_handler(signum, frame):
    global KILL_ME
    KILL_ME = True
    sys.exit(1)

# ############ helper classes/functions ####################################

def args_options():

    # Parser
    parser = argparse.ArgumentParser(prog='stac2resto', formatter_class=argparse.RawDescriptionHelpFormatter, description=textwrap.dedent(USAGE))

    # Process options
    parser.add_argument('STAC_URL', help="STAC endpoint. This could be either a local catalog endpoint (e.g./data/catalog.json) or a remote catalog endpoint (e.g. https://tamn.snapplanet.io)")
    parser.add_argument('--RESTO_URL', help='resto endpoint. Default is "http://host.docker.internal:5252"')
    parser.add_argument('--COLLECTION_DEFAULT_MODEL', help='Default model to apply to new collection if not present in collection.json file (Default is "DefaultModel")')
    parser.add_argument('--INGEST_STRATEGY', help='Ingest strategy defines what is ingested i.e. "collection", "feature" or "both" (Default is "collection")')
    parser.add_argument('--DEVEL', action='store_true', help='Set DEVEL mode on (i.e. deactivate ssl and be verbose)')
    
    return parser

#
# Process catalog url/path
#
def process_stuff(url):

    if KILL_ME == True:
        sys.exit(1)

    # Check between url and path for parsing
    if validators.url(url) is True:
        stuff = read_remote_json(url)
    else:
        try:
            if os.path.exists(url) is False:
                logger.warning("  File %s does not exist - skipping", url)
                return    
            f = open(url)
            stuff = json.load(f)
            f.close()
        except:
            logger.warning("  Cannot open file %s - skipping", url)
            f.close()
            return

    # Not STAC - skip
    if stuff is None or "type" not in stuff:
        logger.warning("  Invalid stac file %s - skipping", url)
        return

    # Post Feature and skip
    if stuff["type"] == "Feature":
        if INGEST_FEATURE:
            post_feature(stuff, url)
        else:
            print(".", end = '')
        return

    # Post FeatureCollection and skip
    if stuff["type"] == "FeatureCollection":
        if INGEST_FEATURE:
            post_features(stuff, url)
        else:
            print(".", end = '')
        return

    # Collection - post collection but continue to explore links after
    if stuff["type"] == "Collection":
        if INGEST_COLLECTION:
            post_collection(stuff)

    # No links skip
    if isinstance(stuff["links"], list) is False:
        logger.warning("  No links to process - skipping")
        return
    
    # Recursively process links
    for link in stuff["links"]:

        # Compute the absolute child url
        child_url = get_absolute_url(url, link["href"])

        if link["rel"] in ["item", "items"] and INGEST_FEATURE:
            process_stuff(child_url)
        elif link["rel"] == "child":
            logger.debug("------------------------------------------------------------------------------------")
            logger.debug("Process %s" % child_url)
            logger.debug("------------------------------------------------------------------------------------")
            process_stuff(child_url)

#
# Compute an absolute url
#
def get_absolute_url(rootUrl, url):
    if validators.url(rootUrl) is True:
        if validators.url(url) is False:
            return urllib3.parse.urljoin(rootUrl, url)
        else:
            return url   
    else:
        return os.path.abspath(os.path.join(os.path.dirname(rootUrl), url))  

#
# Read remote json @ url
#
def read_remote_json(url):

    try:
        stuff = session.get(url, timeout = DEFAULT_TIMEOUT, headers=RESTO_HEADERS, verify=SSL_VERIFY).json()
    except:
        stuff = None
    return stuff


#
# POST a single item to resto
# Example of url: https://explorer.dea.ga.gov.au/collections/s2a_ard_granule/items/0f29a83f-9808-4f39-a822-1accc6085e61
#
def post_collection(collection):

    if 'model' not in collection:
        collection["model"] = COLLECTION_DEFAULT_MODEL
    
    logger.info("  Found collection %s" % (collection["id"]))
    
    # [IMPORTANT] Discard summaries
    del collection["summaries"]

    resp = requests.post("%s/collections" % (RESTO_URL), json=collection, headers=RESTO_HEADERS, verify=SSL_VERIFY)

    # Create collection
    if resp.status_code == 200:
        logger.info("  Create collection %s using model %s to %s" % (collection["id"], COLLECTION_DEFAULT_MODEL, RESTO_URL + '/collections'))

    # HTTP 409 => collection exists. Retry with PUT to update
    elif resp.status_code == 409:
        logger.info("  Update existing collection %s using model %s to %s" % (collection["id"], COLLECTION_DEFAULT_MODEL, RESTO_URL + '/collections'))
        resp = requests.put("%s/collections/%s" % (RESTO_URL, collection["id"]), json=collection, headers=RESTO_HEADERS, verify=SSL_VERIFY)

    # HTTP !== 200 => error
    if resp.status_code != 200:
        logger.error("  " + str(resp.json()))

    return resp.json()


#
# POST a single item to resto
# Example of url: https://explorer.dea.ga.gov.au/collections/s2a_ard_granule/items/0f29a83f-9808-4f39-a822-1accc6085e61
#
def post_feature(feature, url):

    # Get collection from url
    collection_from_url = None
    search_me = re.search(r".*/collections/(.*)/items/.*", url)
    if search_me:
        collection_from_url = search_me.group(1)

    # Assign collection to feature if not set
    if 'collection' not in feature:
        feature["collection"] = collection_from_url
    
    # Collection is not defined neither in feature nor in url
    if feature["collection"] is None:
        logger.error("  Collection is not set - skipping")
        return

    # Check collection conformity
    if collection_from_url and feature["collection"] != collection_from_url:
        logger.error("  Collection from url [%s] differs from collection in feature [%s] - skipping" % (collection_from_url, feature['collection']))
        return
    
    logger.info("  POST Feature %s to %s" % (feature["id"], RESTO_URL + '/collections/' + feature["collection"] + '/items'))
   
    resp = requests.post("%s/collections/%s/items" % (RESTO_URL, feature["collection"]), json=feature, headers=RESTO_HEADERS, verify=SSL_VERIFY)

    # Insert feature
    if resp.status_code == 200:
        logger.info("  Insert feature %s into collection %s" % (feature["id"], feature["collection"]))

    # HTTP 409 => feature exists. Retry with PUT to update
    elif resp.status_code == 409:
        logger.info("  Update existing feature %s" % (feature["id"]))
        resp = requests.put("%s/collections/%s/items/%s" % (RESTO_URL, feature["collection"], feature["id"]), json=feature, headers=RESTO_HEADERS, verify=SSL_VERIFY)

    # HTTP !== 200 => error
    if resp.status_code != 200:
        logger.error("  " + str(resp.json()))

    return resp.json()

#
# POST a FeatureCollection to resto
# Example of url: https://explorer.dea.ga.gov.au/collections/s2a_ard_granule/items
# 
def post_features(features, url, max_features=20):

    logger.info("  POST Features")
    return

    post_features.next_item_url = url
    # From api https://resto/api.html#resto-feature
    headers = {
        'Content-Type': 'application/json',
        'Accept': 'application/json',
        'User-Agent': 'dea-access-resto-ingester/v1'
    }
    collection_id = re.search(r".*/collections/(.*)/items$", url).group(1)
    resto_items_url = "%s/collections/%s/items" % (RESTO_URL, collection_id)

    processed = 0
    while True:
        start_time = time.time()
        logging.info("Retrieve FeatureCollection from: %s" % (post_features.next_item_url))
        try:
            feature_col = session.get(post_features.next_item_url, timeout = DEFAULT_TIMEOUT, headers=headers, verify=SSL_VERIFY, auth=HTTPBasicAuth(API_USER, API_PASSWORD)).json()
            numfeat     = int(feature_col["context"]["returned"])
            logging.info("Retrieved %s features" % (numfeat))
        except requests.ConnectionError as e:
            if re.search('Max retries', str(e), re.IGNORECASE):
                logging.error("Read timed out. Max retries exceeded with url: %s" % e.request.url)
            else:
                logging.error("ConnectionError for URL %s: %s" % (e.request.url, e))
            break
        except requests.RequestException as e:
            logging.error("RequestException for URL %s: %s" % (e.request.url, e))
            break
        else:
            try:

                count = 0
                # POST feature one by one to avoid memory issue with very large FeatureCollection
                for feature in tqdm(feature_col["features"]):
                    try:
                        resp = session.post("%s/collections/%s/items" % (RESTO_URL, collection_id), json=feature, headers=headers, verify=SSL_VERIFY, auth=HTTPBasicAuth(API_USER, API_PASSWORD))
                        resp.raise_for_status()
                        logging.debug(resp.json())
                    except requests.HTTPError as e:
                        if re.search('409 Client Error', str(e), re.IGNORECASE):
                            pass
                        else:
                            logging.error("%s" % str(e))
                            raise SystemExit(1)
                    finally:
                        processed = processed + 1
                        count = count + 1
                        if max_features != -1 and processed >= max_features:
                            break
            except:
                logging.error("POST feature failed")
                break
            else:
                end_time = time.time() - start_time
                numsec = numfeat/end_time
                logging.info("%s features posted to resto (collection: %s) at %s item/s" % (str(count), collection_id, numsec))

                # Stop on page_limit reached
                if max_features != -1 and processed >= max_features:
                    logging.info("Maximum number of features (%s) reached for collection %s" % (str(processed), collection_id))
                    break

                # Search next link if any, or end posting feature
                post_features.next_item_url = None
                for link in feature_col["links"]:
                    if link["rel"] == "next":
                        post_features.next_item_url = link["href"]
                        break

                if post_features.next_item_url is None:
                    logging.info("No more items for collection %s" % (collection_id))
                    break


# ############ end functions ##############################################

# To kill the process on CTRL-C even in the loop
KILL_ME = False
DEFAULT_TIMEOUT = 45 # seconds
SSL_VERIFY      = True

# CTRL-C handler
signal.signal(signal.SIGINT, kill_handler)

parser = args_options()
args = parser.parse_args()

#### Get arguments
if not args:
    usage()

# Get properties for identifierOrPolygon from snapplanet
if 'STAC_URL' in args and args.STAC_URL:
    STAC_URL = args.STAC_URL  
else:
    usage()

# resto endpoint
RESTO_URL = os.environ.get('RESTO_URL') if os.environ.get('RESTO_URL') else 'http://host.docker.internal:5252'
if args and 'RESTO_URL' in args and args.RESTO_URL:
    RESTO_URL = args.RESTO_URL

# Devel
DEVEL = os.environ.get('DEVEL') if os.environ.get('DEVEL') else False
if args and 'DEVEL' in args and args.DEVEL:
    DEVEL = True

# Default model to apply to collection
COLLECTION_DEFAULT_MODEL = os.environ.get('COLLECTION_DEFAULT_MODEL') if os.environ.get('COLLECTION_DEFAULT_MODEL') else 'DefaultModel'
if args and 'COLLECTION_DEFAULT_MODEL' in args and args.COLLECTION_DEFAULT_MODEL:
    COLLECTION_DEFAULT_MODEL = args.COLLECTION_DEFAULT_MODEL

# Color logging
LOG_LEVEL = logging.DEBUG if DEVEL == True else logging.INFO 
LOGFORMAT = "%(log_color)s%(levelname)-8s%(reset)s | %(log_color)s%(message)s%(reset)s"
#LOGFORMAT = "[%(log_color)s%(levelname)s%(reset)s] %(log_color)s%(message)s%(reset)s"
#LOGFORMAT = "%(asctime)s - %(name)s - [%(levelname)s] %(message)s (%(filename)s:%(lineno)d)"
logging.root.setLevel(LOG_LEVEL)
formatter = ColoredFormatter(LOGFORMAT)
stream = logging.StreamHandler()
stream.setLevel(LOG_LEVEL)
stream.setFormatter(formatter)
logger = logging.getLogger('stac2resto')
logger.setLevel(LOG_LEVEL)
logger.addHandler(stream)

# Ingest collection, feature or both
INGEST_STRATEGY = os.environ.get('INGEST_STRATEGY') if os.environ.get('INGEST_STRATEGY') else 'collection'
if args and 'INGEST_STRATEGY' in args and args.INGEST_STRATEGY:
    INGEST_STRATEGY = args.INGEST_STRATEGY

if INGEST_STRATEGY == 'collection':
    INGEST_COLLECTION = True
    INGEST_FEATURE = False
elif INGEST_STRATEGY == 'feature':
    INGEST_FEATURE = True
    INGEST_COLLECTION = False
elif INGEST_STRATEGY == 'both':
    INGEST_COLLECTION = True
    INGEST_FEATURE = True
elif INGEST_STRATEGY == 'none':
    INGEST_FEATURE = False
    INGEST_COLLECTION = False
else:
    usage("Unknown INGEST_STRATEGY - should be one of \"collection\", \"feature\", \"both\" or \"none\"")

# Snapplanet_auth_token is mandatory
RESTO_ADMIN_AUTH_TOKEN = os.environ.get("RESTO_ADMIN_AUTH_TOKEN")
if args and 'authToken' in args and args.authToken:
    RESTO_ADMIN_AUTH_TOKEN = args.authToken

if RESTO_ADMIN_AUTH_TOKEN is None:
    usage("Missing mandatory environement variable RESTO_ADMIN_AUTH_TOKEN")

if RESTO_URL is None:
    usage("Missing mandatory target RESTO_URL")

if DEVEL:
    SSL_VERIFY=False
    logger.debug("Devel set to %s" % DEVEL)
    logger.debug("Disable warnings for insecure ssl request in urllib3")
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
    logger.debug("Setting requests verify to %s", SSL_VERIFY )

RETRY_STRATEGY = Retry(
    total=50,
    backoff_factor=2,
    status_forcelist=[ 429, 500, 502, 503, 504 ], # Retry on these error codes. Might have to add more in future. depends on explorer API errors.
    method_whitelist=[ "HEAD", "GET", "POST" ]
)

RESTO_HEADERS = {
    'Content-Type': 'application/json',
    'Accept': 'application/json',
    'User-Agent': 'stac2resto',
    'Authorization': 'Bearer ' + RESTO_ADMIN_AUTH_TOKEN
}

# post items to resto according to item type: item, items, collection, etc.
logger.debug("Input STAC endpoint is %s " % (STAC_URL))
logger.debug("Target resto endpoint is %s " % RESTO_URL)
logger.debug("RESTO_ADMIN_AUTH_TOKEN is set to %s " % RESTO_ADMIN_AUTH_TOKEN)

session = requests.Session()
adapter = HTTPAdapter(max_retries=RETRY_STRATEGY)
session.mount(RESTO_URL.split('://')[0] + '://', adapter)

# Iterative process
logger.debug("------------------------------------------------------------------------------------")
logger.debug("Process %s" % STAC_URL)
logger.debug("------------------------------------------------------------------------------------")
process_stuff(STAC_URL)
